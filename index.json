[{"content":"","date":"13 February 2026","externalUrl":null,"permalink":"/tags/agentic-development/","section":"Tags","summary":"","title":"Agentic-Development","type":"tags"},{"content":"","date":"13 February 2026","externalUrl":null,"permalink":"/tags/ai/","section":"Tags","summary":"","title":"Ai","type":"tags"},{"content":"","date":"13 February 2026","externalUrl":null,"permalink":"/categories/ai/","section":"Categories","summary":"","title":"AI","type":"categories"},{"content":"","date":"13 February 2026","externalUrl":null,"permalink":"/tags/anthropic/","section":"Tags","summary":"","title":"Anthropic","type":"tags"},{"content":"","date":"13 February 2026","externalUrl":null,"permalink":"/tags/aws/","section":"Tags","summary":"","title":"AWS","type":"tags"},{"content":"","date":"13 February 2026","externalUrl":null,"permalink":"/tags/aws-bedrock/","section":"Tags","summary":"","title":"Aws-Bedrock","type":"tags"},{"content":"","date":"13 February 2026","externalUrl":null,"permalink":"/tags/bedrock/","section":"Tags","summary":"","title":"Bedrock","type":"tags"},{"content":"","date":"13 February 2026","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","date":"13 February 2026","externalUrl":null,"permalink":"/tags/claude/","section":"Tags","summary":"","title":"Claude","type":"tags"},{"content":"","date":"13 February 2026","externalUrl":null,"permalink":"/tags/cli/","section":"Tags","summary":"","title":"Cli","type":"tags"},{"content":"","date":"13 February 2026","externalUrl":null,"permalink":"/categories/development/","section":"Categories","summary":"","title":"Development","type":"categories"},{"content":"","date":"13 February 2026","externalUrl":null,"permalink":"/tags/generative-ai/","section":"Tags","summary":"","title":"Generative-Ai","type":"tags"},{"content":"","date":"13 February 2026","externalUrl":null,"permalink":"/","section":"Krzysztof's Blog","summary":"","title":"Krzysztof's Blog","type":"page"},{"content":"","date":"13 February 2026","externalUrl":null,"permalink":"/tags/mcp/","section":"Tags","summary":"","title":"Mcp","type":"tags"},{"content":"","date":"13 February 2026","externalUrl":null,"permalink":"/tags/oh-my-opencode/","section":"Tags","summary":"","title":"Oh-My-Opencode","type":"tags"},{"content":"","date":"13 February 2026","externalUrl":null,"permalink":"/tags/opencode/","section":"Tags","summary":"","title":"Opencode","type":"tags"},{"content":"","date":"13 February 2026","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":"","date":"13 February 2026","externalUrl":null,"permalink":"/tags/productivity/","section":"Tags","summary":"","title":"Productivity","type":"tags"},{"content":"","date":"13 February 2026","externalUrl":null,"permalink":"/tags/programming/","section":"Tags","summary":"","title":"Programming","type":"tags"},{"content":"After a few months of experimenting with AI coding assistants, I\u0026rsquo;ve settled on a setup that significantly accelerates my development workflow. This post walks through configuring Opencode with AWS Bedrock, the oh-my-opencode plugin for multi-agent orchestration, and various plugins and skills that make the whole system more powerful.\nWhy This Setup? # A few reasons I landed on this particular combination:\nModel flexibility: Opencode works with any LLM provider - Anthropic direct, AWS Bedrock, OpenAI, local models via Ollama. No vendor lock-in. Cost management: AWS Bedrock with cross-region inference gives access to Claude Opus 4.5, Sonnet 4.5, and Haiku 4.5 with AWS billing - useful if you\u0026rsquo;re already in the AWS ecosystem. Multi-agent orchestration: Oh-my-opencode adds specialized sub-agents that can work in parallel on different aspects of a task. Extensibility: MCP servers, plugins, and skills let you customize the experience for your specific workflows. The Architecture # The setup consists of several layers:\nLayer Purpose Opencode CLI Core agentic coding interface (TUI or CLI) oh-my-opencode Multi-agent orchestration plugin AWS Bedrock LLM provider with Claude models MCP Servers External tool integrations Plugins System-level extensions Skills Reusable knowledge modules Prerequisites # Before starting, you\u0026rsquo;ll need:\nNode.js v18 or later An AWS account with Bedrock access enabled AWS CLI configured with credentials (aws configure) Basic comfort with the terminal Step 1: Install Opencode # # Install globally via npm npm install -g @opencode-ai/cli # Or use npx to run directly npx opencode Verify the installation:\nopencode --version Step 2: Configure AWS Bedrock # Opencode supports AWS Bedrock out of the box. The model format is amazon-bedrock/\u0026lt;model-id\u0026gt;.\nFor cross-region inference (recommended for better availability), use the global. prefix:\namazon-bedrock/global.anthropic.claude-opus-4-5-20251101-v1:0 amazon-bedrock/global.anthropic.claude-sonnet-4-5-20250929-v1:0 amazon-bedrock/global.anthropic.claude-haiku-4-5-20251001-v1:0 Make sure your AWS credentials are configured:\n# Check your current identity aws sts get-caller-identity # If not configured, run: aws configure You\u0026rsquo;ll need appropriate IAM permissions for Bedrock. At minimum:\nbedrock:InvokeModel bedrock:InvokeModelWithResponseStream Step 3: Install Oh-My-Opencode # Oh-my-opencode is the plugin that transforms Opencode into a multi-agent system. It adds specialized agents that can work in parallel on different aspects of your tasks.\n# Add to your opencode config # In ~/.config/opencode/opencode.json, add to the plugin array: Edit ~/.config/opencode/opencode.json:\n{ \u0026#34;$schema\u0026#34;: \u0026#34;https://opencode.ai/config.json\u0026#34;, \u0026#34;plugin\u0026#34;: [ \u0026#34;oh-my-opencode@latest\u0026#34; ] } Configure Agent Models # Create ~/.config/opencode/oh-my-opencode.json to specify which models each agent uses:\n{ \u0026#34;$schema\u0026#34;: \u0026#34;https://raw.githubusercontent.com/code-yeongyu/oh-my-opencode/master/assets/oh-my-opencode.schema.json\u0026#34;, \u0026#34;agents\u0026#34;: { \u0026#34;sisyphus\u0026#34;: { \u0026#34;model\u0026#34;: \u0026#34;amazon-bedrock/global.anthropic.claude-opus-4-5-20251101-v1:0\u0026#34; }, \u0026#34;oracle\u0026#34;: { \u0026#34;model\u0026#34;: \u0026#34;amazon-bedrock/global.anthropic.claude-sonnet-4-5-20250929-v1:0\u0026#34; }, \u0026#34;librarian\u0026#34;: { \u0026#34;model\u0026#34;: \u0026#34;amazon-bedrock/global.anthropic.claude-sonnet-4-5-20250929-v1:0\u0026#34; }, \u0026#34;explore\u0026#34;: { \u0026#34;model\u0026#34;: \u0026#34;amazon-bedrock/global.anthropic.claude-haiku-4-5-20251001-v1:0\u0026#34; } }, \u0026#34;categories\u0026#34;: { \u0026#34;visual-engineering\u0026#34;: { \u0026#34;model\u0026#34;: \u0026#34;amazon-bedrock/global.anthropic.claude-sonnet-4-5-20250929-v1:0\u0026#34; }, \u0026#34;ultrabrain\u0026#34;: { \u0026#34;model\u0026#34;: \u0026#34;amazon-bedrock/global.anthropic.claude-opus-4-5-20251101-v1:0\u0026#34; }, \u0026#34;quick\u0026#34;: { \u0026#34;model\u0026#34;: \u0026#34;amazon-bedrock/global.anthropic.claude-haiku-4-5-20251001-v1:0\u0026#34; } } } The Agent Hierarchy # Oh-my-opencode provides several specialized agents:\nAgent Role Recommended Model Sisyphus Main orchestrator, handles complex multi-step tasks Opus (expensive but capable) Oracle High-quality consultation for architecture decisions Sonnet Librarian Research external docs, examples, best practices Sonnet Explore Fast codebase exploration, pattern discovery Haiku (cheap, fast) Hephaestus Implementation-focused agent Opus or Sonnet The key insight is model tiering: use expensive models (Opus) for complex reasoning, mid-tier (Sonnet) for most tasks, and cheap models (Haiku) for exploration and simple operations.\nStep 4: Add Useful Plugins # Plugins extend Opencode\u0026rsquo;s capabilities at the system level. Here are some I find useful:\n{ \u0026#34;plugin\u0026#34;: [ \u0026#34;oh-my-opencode@latest\u0026#34;, \u0026#34;@mathew-cf/opencode-terminal-notifier\u0026#34;, \u0026#34;envsitter-guard@latest\u0026#34;, \u0026#34;@tarquinen/opencode-smart-title\u0026#34;, \u0026#34;opencode-wakatime\u0026#34; ] } Plugin Purpose terminal-notifier Desktop notifications when tasks complete envsitter-guard Prevents accidental exposure of .env secrets smart-title Auto-generates meaningful session titles wakatime Tracks coding time for productivity metrics Step 5: Configure MCP Servers # MCP (Model Context Protocol) servers give Opencode access to external tools and data sources. Add them to your opencode.json:\n{ \u0026#34;mcp\u0026#34;: { \u0026#34;awslabs.aws-documentation-mcp-server\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;command\u0026#34;: [\u0026#34;uvx\u0026#34;, \u0026#34;awslabs.aws-documentation-mcp-server@latest\u0026#34;], \u0026#34;environment\u0026#34;: { \u0026#34;FASTMCP_LOG_LEVEL\u0026#34;: \u0026#34;ERROR\u0026#34; }, \u0026#34;enabled\u0026#34;: true, \u0026#34;timeout\u0026#34;: 120000 }, \u0026#34;awslabs.cdk-mcp-server\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;command\u0026#34;: [\u0026#34;uvx\u0026#34;, \u0026#34;awslabs.cdk-mcp-server@latest\u0026#34;], \u0026#34;enabled\u0026#34;: true }, \u0026#34;smart-connections\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;command\u0026#34;: [\u0026#34;node\u0026#34;, \u0026#34;/path/to/smart-connections-mcp/dist/index.js\u0026#34;], \u0026#34;environment\u0026#34;: { \u0026#34;SMART_VAULT_PATH\u0026#34;: \u0026#34;/path/to/obsidian/vault\u0026#34; }, \u0026#34;enabled\u0026#34;: true } } } Some MCP servers I use regularly:\nServer Purpose aws-documentation Query AWS docs directly cdk-mcp-server CDK construct information smart-connections Semantic search over Obsidian notes excel Read/write Excel files Step 6: Install Skills # Skills are reusable knowledge modules that agents can load on-demand. They\u0026rsquo;re markdown files that give agents specialized knowledge about specific topics.\n# Skills are stored in ~/.config/opencode/skills/ # Each skill is a directory with a SKILL.md file # Install a skill from the ecosystem npx skills add jackspace/claudeskillz@hugo # Or create your own mkdir -p ~/.config/opencode/skills/my-skill # Add SKILL.md with your specialized knowledge Skills I currently have installed:\nhugo - Static site generation with Hugo git-commit - Conventional commit message formatting manimce-best-practices - Manim animation library patterns obsidian - Obsidian vault interaction Step 7: Create an AGENTS.md # The AGENTS.md file in ~/.config/opencode/ provides global instructions that all agents follow. This is where you codify your engineering principles:\n# Engineering Principles You are a senior software engineer embedded in an agentic coding workflow. ## Core Behaviors ### Assumption Surfacing (Critical) Before implementing anything non-trivial, explicitly state your assumptions: - Never silently fill in ambiguous requirements - Surface uncertainty early ### Push Back When Warranted You are not a yes-machine. When the human\u0026#39;s approach has clear problems: - Point out the issue directly - Propose an alternative - Accept their decision if they override ### Simplicity Enforcement Prefer the boring, obvious solution. Cleverness is expensive. This ensures consistent behavior across all agents and sessions.\nPractical Workflows # Parallel Exploration # When tackling an unfamiliar codebase, fire multiple explore agents in parallel:\n\u0026gt; Search for authentication patterns in this repo \u0026gt; Also look for how error handling is done \u0026gt; And find the database access patterns The explore agent (running Haiku) quickly surfaces patterns while you focus on the main task.\nDelegating to Specialists # For complex tasks, the main agent can delegate to specialists:\n\u0026gt; Implement a new REST endpoint for user preferences Behind the scenes, Sisyphus might:\nFire explore to understand existing endpoint patterns Consult oracle for architecture decisions Delegate implementation to a sub-agent Run verification Research-Heavy Tasks # For tasks requiring external knowledge:\n\u0026gt; How should I implement DynamoDB single-table design for this use case? The librarian agent queries documentation, finds examples on GitHub, and synthesizes recommendations - all without you leaving the terminal.\nCost Considerations # With AWS Bedrock, you pay per token. Model tiering helps manage costs:\nModel Use Case Relative Cost Haiku 4.5 Exploration, simple tasks $ Sonnet 4.5 Most coding tasks $$ Opus 4.5 Complex reasoning, architecture $$$ My configuration uses Haiku for explore and quick categories, Sonnet for most work, and reserves Opus for ultrabrain and main orchestration.\nTroubleshooting # \u0026ldquo;Model not found\u0026rdquo; errors # Ensure you\u0026rsquo;ve enabled the specific Claude models in your AWS Bedrock console. Cross-region inference models require explicit enablement.\nSlow responses # Check your AWS region. Cross-region inference (global. prefix) routes to the nearest available region but can add latency. Consider using region-specific model IDs if latency is critical.\nPlugin installation issues # # Clear plugin cache rm -rf ~/.config/opencode/node_modules rm ~/.config/opencode/package-lock.json # Reinstall opencode MCP server timeouts # Increase the timeout in your config:\n{ \u0026#34;mcp\u0026#34;: { \u0026#34;server-name\u0026#34;: { \u0026#34;timeout\u0026#34;: 180000 } } } Resources # Opencode Documentation - Official docs oh-my-opencode GitHub - Multi-agent plugin AWS Bedrock Claude Models - Model availability MCP Specification - Model Context Protocol This setup has become central to my daily development workflow. Curious to hear how others are configuring their agentic development environments - what models, plugins, or workflows have you found effective?\n","date":"13 February 2026","externalUrl":null,"permalink":"/posts/opencode-aws-bedrock-setup/","section":"Posts","summary":"","title":"Supercharging Opencode with AWS Bedrock, Oh-My-Opencode, and Custom Skills","type":"posts"},{"content":"","date":"13 February 2026","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":"","date":"13 February 2026","externalUrl":null,"permalink":"/categories/tools/","section":"Categories","summary":"","title":"Tools","type":"categories"},{"content":"⚠️ Model IDs change frequently: The model IDs and configuration in this guide reflect the state at the time of writing. Anthropic regularly releases new Claude versions on Bedrock. Always check the AWS Bedrock supported models documentation and Bedrock model IDs reference for the most current model identifiers and regional availability.\nClaude Code is a powerful CLI tool that allows you to interact with Claude AI models directly from your terminal. This guide will walk you through setting up Claude Code to work with Amazon Bedrock as the backend provider.\nWhat is Claude Code? # Claude Code is a powerful CLI tool that brings Claude\u0026rsquo;s AI capabilities to your terminal. It provides an interactive coding assistant that understands your local files and can help with various software engineering tasks.\nCheck out this video for a quick overview of Claude Code in action:\nPrerequisites # AWS account with Bedrock access enabled Node.js (v14 or later) and npm installed on your system AWS CLI installed and configured with appropriate permissions Access to Anthropic Claude models in your AWS Bedrock account (Claude Sonnet 4.5 recommended) Setup Steps # Install Claude Code CLI\nInstall the official Claude Code CLI tool from Anthropic:\nnpm install -g @anthropic-ai/claude-code You can verify the installation was successful by running:\nclaude --version For detailed installation instructions, refer to the official Claude Code documentation.\nConfigure AWS Credentials\nEnsure your AWS credentials are properly configured with permissions for Bedrock:\naws configure You\u0026rsquo;ll need to enter:\nAWS Access Key ID AWS Secret Access Key Default region name (use a region where Claude models are available, like us-east-1) Default output format (recommended: json) For IAM permissions, your user/role needs:\nbedrock:InvokeModel bedrock:InvokeModelWithResponseStream bedrock:ListFoundationModels bedrock:ListInferenceProfiles For detailed AWS credentials setup, see the AWS CLI Configuration Guide.\nEnable Claude Model Access in Bedrock\nNavigate to the AWS Bedrock console in a supported region (e.g., us-east-1)\nComplete Bedrock onboarding if needed (accept terms and conditions)\nGo to \u0026ldquo;Model access\u0026rdquo; → \u0026ldquo;Manage model access\u0026rdquo;\nFind \u0026ldquo;Anthropic\u0026rdquo; and enable the Claude models you want to use:\nClaude Sonnet 4.5 (recommended) - global.anthropic.claude-sonnet-4-5-20250929-v1:0 Claude Opus 4.6 (most capable) - for complex reasoning and agentic tasks Claude Haiku 4.5 (fast/cheap) - us.anthropic.claude-haiku-4-5-20251001-v1:0 Click \u0026ldquo;Request model access\u0026rdquo; and \u0026ldquo;Save changes\u0026rdquo;\nWait a few minutes for access to be granted (status will change from \u0026ldquo;Pending\u0026rdquo; to \u0026ldquo;Access granted\u0026rdquo;)\nYou can verify access using the AWS CLI:\naws bedrock list-foundation-models --region us-east-1 | grep anthropic.claude If you encounter issues, check that your account has completed Bedrock onboarding and review service quotas in your selected region.\nSet Environment Variables\nTo tell Claude Code to use Bedrock as its backend, you need to set some environment variables. These are special settings that tell the software which model to use and where to find it.\nQuick Start (Temporary Use) # If you just want to try Claude Code with Bedrock quickly, you can run these commands in your terminal before using Claude:\n# Copy and paste these lines into your terminal export ANTHROPIC_MODEL=\u0026#39;global.anthropic.claude-sonnet-4-5-20250929-v1:0\u0026#39; export CLAUDE_CODE_USE_BEDROCK=1 After running these commands in your terminal window, you can immediately use Claude Code with Bedrock by running claude commands in that same terminal window. However, these settings will only last until you close that terminal window.\nFor US East Region (Virginia) # If you\u0026rsquo;re using the US East region (which is the default for many AWS accounts):\nexport AWS_REGION=\u0026#39;us-east-1\u0026#39; Optional: Configure Haiku Model # Claude Code uses a smaller/faster model for some operations. By default, it auto-selects the Haiku model, but you can manually specify it:\nexport ANTHROPIC_SMALL_FAST_MODEL=\u0026#39;us.anthropic.claude-haiku-4-5-20251001-v1:0\u0026#39; For Permanent Configuration # To avoid having to set these variables every time, you can make them permanent by adding them to your shell\u0026rsquo;s configuration file:\nOpen your shell configuration file in a text editor:\nFor Mac/Linux with Bash: nano ~/.bashrc or nano ~/.bash_profile For Mac with Zsh: nano ~/.zshrc For Fish shell: nano ~/.config/fish/config.fish Add these lines at the end of the file:\n# Claude Code Bedrock configuration export ANTHROPIC_MODEL=\u0026#39;global.anthropic.claude-sonnet-4-5-20250929-v1:0\u0026#39; export CLAUDE_CODE_USE_BEDROCK=1 export AWS_REGION=\u0026#39;us-east-1\u0026#39; # Change this if using a different region # Optional: explicitly set Haiku model version # export ANTHROPIC_SMALL_FAST_MODEL=\u0026#39;us.anthropic.claude-haiku-4-5-20251001-v1:0\u0026#39; Save the file and exit the editor\nIn nano: Press Ctrl+O to save, then Enter, then Ctrl+X to exit Apply the changes by reloading your configuration:\n# For bash (choose one depending on which file you edited) source ~/.bashrc # OR source ~/.bash_profile # For zsh source ~/.zshrc # For fish source ~/.config/fish/config.fish After completing these steps, Claude Code will use Bedrock in all your terminal sessions.\nUsing Claude Code with Bedrock # Claude Code has access to the directory where it\u0026rsquo;s executed, allowing it to analyze your project files, understand your codebase, and assist with development tasks. It guides you through complex processes by suggesting next steps and requesting permission before running commands that modify your files or system.\nOnce configured with Bedrock, you can start using Claude Code with commands like:\n# Run Claude in interactive mode (most useful way to use Claude Code) claude # Ask Claude a question claude \u0026#34;How do I optimize Docker images?\u0026#34; # Run Claude with context from specific files claude --context path/to/file.py \u0026#34;Explain this code\u0026#34; # Multiple contexts for more comprehensive analysis claude --context file1.js --context file2.js \u0026#34;How do these components interact?\u0026#34; Benefits of Using Bedrock Backend # Data privacy - your queries stay within your AWS environment Cost management through AWS billing Access control through IAM policies Lower latency (depending on region configuration) Integration with AWS Guardrails for content filtering Alternative Authentication Methods # Using AWS SSO # If your organization uses AWS SSO, you can configure Claude Code to automatically refresh credentials:\nCreate or edit ~/.claude/settings.json:\n{ \u0026#34;awsAuthRefresh\u0026#34;: \u0026#34;aws sso login --profile myprofile\u0026#34;, \u0026#34;env\u0026#34;: { \u0026#34;AWS_PROFILE\u0026#34;: \u0026#34;myprofile\u0026#34; } } Claude Code will automatically detect expired credentials and run the refresh command.\nUsing Bedrock API Keys (Simplified Auth) # For simpler setups without full AWS CLI configuration, you can use Bedrock API Keys:\nexport AWS_BEARER_TOKEN_BEDROCK=your-bedrock-api-key export CLAUDE_CODE_USE_BEDROCK=1 This eliminates the need for AWS CLI configuration and is ideal for developers who only need Bedrock access.\nEnterprise Features # AWS Guardrails Integration # You can implement content filtering via Bedrock Guardrails by adding custom headers:\n{ \u0026#34;env\u0026#34;: { \u0026#34;ANTHROPIC_CUSTOM_HEADERS\u0026#34;: \u0026#34;X-Amzn-Bedrock-GuardrailIdentifier: your-guardrail-id\\nX-Amzn-Bedrock-GuardrailVersion: 1\u0026#34; } } This is useful for compliance-focused organizations that need to filter or moderate AI responses.\nTroubleshooting # If you encounter issues with Claude Code using Bedrock, try these troubleshooting steps:\nConnection and Authentication Issues # Verify AWS Credentials and Permissions\n# Check if your credentials are properly configured aws sts get-caller-identity # Verify you have Bedrock access aws bedrock list-foundation-models --region us-east-1 Confirm Model Access\n# Check if Claude Sonnet 4.5 is available to your account aws bedrock list-foundation-models --query \u0026#34;modelSummaries[?contains(modelId, \u0026#39;claude\u0026#39;)]\u0026#34; --region us-east-1 Region Configuration\nEnsure your AWS_REGION environment variable (or default region) is set to a region where Claude models are available Verify model availability in your region in the Bedrock service endpoints documentation Common Error Messages # \u0026ldquo;AccessDeniedException\u0026rdquo; - Check IAM permissions; your user/role needs bedrock:InvokeModel permission\n\u0026ldquo;ValidationException: Model not found\u0026rdquo; - Verify model ID and region compatibility\n\u0026ldquo;ResourceNotFoundException\u0026rdquo; - Ensure you\u0026rsquo;ve completed model access approval\n\u0026ldquo;ThrottlingException\u0026rdquo; or \u0026ldquo;429 Too many tokens, please wait before trying again.\u0026rdquo; - You may have exceeded your quota or rate limit. When this happens, the Claude CLI will display a message saying \u0026ldquo;429 Too many tokens, please wait before trying again.\u0026rdquo; This is because AWS Bedrock enforces rate limits on API requests to prevent abuse and ensure fair resource allocation across all users.\nWhat\u0026rsquo;s happening: AWS Bedrock has token rate limits that restrict how many tokens you can process within a specific timeframe (usually per minute). When you exceed this limit, AWS returns a 429 error code (Too Many Requests), which Claude CLI then displays as a user-friendly message.\nHow to fix it:\nWait a few minutes before trying again to allow your token quota to refresh For production applications, implement exponential backoff and retry logic If you consistently hit limits, request a quota increase through the AWS Service Quotas console Check your Bedrock quotas to understand your current limits Environment Debugging # Run Claude Code with debug logging enabled:\nDEBUG=* claude \u0026#34;Your prompt here\u0026#34; For persistent issues, you can check AWS CloudTrail logs to see if your Bedrock API calls are being made and any errors they\u0026rsquo;re returning:\naws cloudtrail lookup-events --lookup-attributes AttributeKey=EventName,AttributeValue=InvokeModel For more comprehensive troubleshooting and documentation:\nClaude Code documentation AWS Bedrock documentation AWS Bedrock troubleshooting guide Meta: How This Post Was Created # This post was originally created using Claude Code CLI in interactive mode, shortly after Claude Code\u0026rsquo;s initial release when there were no mature open-source alternatives. The initial content and featured image were generated entirely through AI-assisted conversation.\nSince then, the post has been significantly refactored and updated to reflect the latest model versions and configuration options.\nAuthor\u0026rsquo;s note: I have since migrated my AI coding workflow to OpenCode and AWS Kiro - both excellent alternatives that emerged after Claude Code\u0026rsquo;s launch. This post remains relevant for those who prefer or need to use Claude Code with Bedrock.\n","date":"13 February 2026","externalUrl":null,"permalink":"/posts/using-claude-code-with-bedrock/","section":"Posts","summary":"","title":"Using Claude Code with Bedrock Backend","type":"posts"},{"content":"","date":"12 February 2026","externalUrl":null,"permalink":"/tags/kiro/","section":"Tags","summary":"","title":"Kiro","type":"tags"},{"content":"","date":"12 February 2026","externalUrl":null,"permalink":"/tags/knowledge-management/","section":"Tags","summary":"","title":"Knowledge-Management","type":"tags"},{"content":"","date":"12 February 2026","externalUrl":null,"permalink":"/tags/obsidian/","section":"Tags","summary":"","title":"Obsidian","type":"tags"},{"content":"A few colleagues recently saw my Obsidian setup and asked how I get AI agents to search my notes semantically - not just keyword matching, but actually understanding what I\u0026rsquo;m looking for. The answer is a combination of three tools: Smart Connections for local embeddings, MCP (Model Context Protocol) for exposing those embeddings to AI agents, and optionally the new Obsidian CLI for write operations.\nThis post walks through the complete setup and shares some practical workflows I\u0026rsquo;ve found useful.\nWhy This Setup? # Before diving into the how, let\u0026rsquo;s address the why:\nLocal embeddings: All embeddings are computed and stored locally using Smart Connections\u0026rsquo; bundled model. Your notes aren\u0026rsquo;t sent anywhere for embedding generation. (Note: when AI agents query results via MCP, the retrieved content is sent to your configured LLM provider - AWS Bedrock, Anthropic, etc. - unless you use a fully local setup like Ollama.) Semantic search: Find notes by meaning, not just keywords. \u0026ldquo;Find notes about conference talk ideas\u0026rdquo; works even if none of your notes contain those exact words. AI-native: AI agents (Opencode, Kiro CLI) can query your knowledge base directly through MCP tools. Zero embedding costs: Smart Connections bundles a local embedding model - no OpenAI API calls needed for generating embeddings. The Architecture # Here\u0026rsquo;s how the pieces fit together:\nPrerequisites # Before starting, you\u0026rsquo;ll need:\nObsidian installed with a vault containing some notes Node.js v18 or later An MCP-compatible client (Opencode, Kiro CLI, or similar) Basic comfort with the terminal Step 1: Install Smart Connections Plugin # Smart Connections is an Obsidian plugin that generates embeddings for your notes locally.\nOpen Obsidian Settings → Community plugins Disable Safe mode if prompted Click Browse and search for \u0026ldquo;Smart Connections\u0026rdquo; Install and enable the plugin Initial Embedding Generation # After enabling the plugin, it will start generating embeddings for your notes in the background. You can monitor progress in the Smart Connections panel (click the brain icon in the sidebar).\nImportant notes:\nFirst-time embedding generation takes a few minutes depending on vault size Notes shorter than ~200 characters won\u0026rsquo;t be embedded Embeddings are stored in .smart-env/ folder in your vault The plugin uses TaylorAI/bge-micro-v2 model (384 dimensions) by default You can verify embeddings are working by using the Smart Connections panel - it should show semantically similar notes when you open any note.\nStep 2: Set Up the MCP Server # The smart-connections-mcp server exposes your Smart Connections embeddings via MCP protocol.\n# Clone the repository git clone https://github.com/msdanyg/smart-connections-mcp.git # I recommend placing it in a standard location mkdir -p ~/.local/share/mcp-servers mv smart-connections-mcp ~/.local/share/mcp-servers/ # Install dependencies and build cd ~/.local/share/mcp-servers/smart-connections-mcp npm install npm run build The server provides six MCP tools:\nTool Description search_notes Semantic search using text queries get_similar_notes Find notes similar to a given note get_connection_graph Build multi-level relationship graphs get_embedding_neighbors Direct vector similarity queries get_note_content Retrieve note content with block extraction get_stats Knowledge base statistics Step 3: Configure Your MCP Client # For Opencode # Add the server to your ~/.config/opencode/opencode.json:\n{ \u0026#34;mcp\u0026#34;: { \u0026#34;smart-connections\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;local\u0026#34;, \u0026#34;command\u0026#34;: [ \u0026#34;node\u0026#34;, \u0026#34;/Users/YOUR_USERNAME/.local/share/mcp-servers/smart-connections-mcp/dist/index.js\u0026#34; ], \u0026#34;environment\u0026#34;: { \u0026#34;SMART_VAULT_PATH\u0026#34;: \u0026#34;/path/to/your/obsidian/vault\u0026#34; }, \u0026#34;enabled\u0026#34;: true, \u0026#34;timeout\u0026#34;: 120000 } } } For Kiro CLI # Kiro uses the same MCP configuration format. Add to your Kiro config:\n{ \u0026#34;mcpServers\u0026#34;: { \u0026#34;smart-connections\u0026#34;: { \u0026#34;command\u0026#34;: \u0026#34;node\u0026#34;, \u0026#34;args\u0026#34;: [\u0026#34;/Users/YOUR_USERNAME/.local/share/mcp-servers/smart-connections-mcp/dist/index.js\u0026#34;], \u0026#34;env\u0026#34;: { \u0026#34;SMART_VAULT_PATH\u0026#34;: \u0026#34;/path/to/your/obsidian/vault\u0026#34; } } } } For Other MCP Clients # Other MCP-compatible clients (Claude Desktop, Claude Code, etc.) follow similar patterns - you\u0026rsquo;ll need to specify the command, arguments, and environment variables pointing to your vault. Check your client\u0026rsquo;s documentation for the exact configuration format.\nRemember to replace:\nYOUR_USERNAME with your actual username /path/to/your/obsidian/vault with the absolute path to your Obsidian vault Step 4: Verify the Setup # Restart your MCP client and test the connection. In Opencode, try:\n\u0026ldquo;Search my notes for anything related to conference talks\u0026rdquo;\nIf configured correctly, the AI will use the search_notes tool and return semantically relevant results from your vault.\nYou can also check the stats:\n\u0026ldquo;Show me statistics about my knowledge base\u0026rdquo;\nThis should return something like:\nTotal notes: 137 Total blocks: 892 Embedding dimension: 384 Model: TaylorAI/bge-micro-v2 Practical Workflows # Here are some workflows I\u0026rsquo;ve found genuinely useful:\nAggregating Ideas for Conference Talks # This is the workflow that impressed my colleagues. I had a large backlog of scattered notes - ideas, observations, half-formed thoughts about various topics. Getting AI to aggregate them semantically was a game-changer:\n\u0026ldquo;Search my notes for ideas related to async Python programming. Then find notes similar to the top results to expand the search. Summarize the key themes.\u0026rdquo;\nThe AI chains search_notes with get_similar_notes to build a comprehensive picture, then synthesizes it into actionable themes.\nRefactoring Notes for Different Audiences # When submitting to different conferences, I need to adjust the messaging. Same core ideas, different framing:\n\u0026ldquo;Find my notes about serverless architectures. Summarize them in a way that would fit a call for papers focused on cost optimization.\u0026rdquo;\n\u0026ldquo;Now reframe the same content for a developer experience angle.\u0026rdquo;\nBuilding Connection Graphs # Understanding how your notes relate to each other:\n\u0026ldquo;Build a connection graph starting from my note \u0026lsquo;AI-assisted development.md\u0026rsquo; with depth 3. What clusters of related topics emerge?\u0026rdquo;\nThe get_connection_graph tool returns hierarchical relationships that reveal hidden connections between ideas.\nQuick Knowledge Base Queries # Day-to-day lookups when you can\u0026rsquo;t remember where you wrote something:\n\u0026ldquo;Find notes where I discussed trade-offs between DynamoDB and PostgreSQL\u0026rdquo;\n\u0026ldquo;What did I write about error handling patterns?\u0026rdquo;\nThe New Obsidian CLI (v1.12.0) # Obsidian recently released a CLI (February 2026) that complements this setup nicely. While the MCP server provides read-only semantic access, the CLI enables write operations:\n# Create a new note obsidian create \u0026#34;Meeting Notes/2025-02-12.md\u0026#34; # Append content to a note obsidian append \u0026#34;Ideas/conference-talks.md\u0026#34; \u0026#34;New idea: ...\u0026#34; # Read daily note obsidian daily:read # Manage properties obsidian property:set \u0026#34;note.md\u0026#34; status \u0026#34;published\u0026#34; Combined Workflow: AI Search → CLI Write # The real power comes from combining MCP (read) with CLI (write):\nAI searches your vault via MCP: \u0026ldquo;Find all notes tagged #draft about Python\u0026rdquo; AI analyzes and suggests consolidation You approve, AI executes via CLI to create new consolidated note This isn\u0026rsquo;t fully automated yet (the AI can\u0026rsquo;t directly invoke CLI commands), but the pattern is emerging. Some users are already scripting this with shell commands.\nPerformance Notes # From my experience with a ~150 note vault:\nInitial load: 2-5 seconds for the MCP server to read embeddings Search queries: \u0026lt;50ms typically Memory usage: ~20-30MB for the server Embedding generation: Happens automatically when you edit notes in Obsidian The embeddings themselves are small - the .smart-env folder is usually under 10MB even for large vaults.\nTroubleshooting # \u0026ldquo;Server not found\u0026rdquo; or connection errors # Verify the path in your config is absolute and correct Check that npm run build completed successfully Ensure SMART_VAULT_PATH points to a vault with Smart Connections enabled Restart your MCP client after config changes Empty search results # Make sure Smart Connections has finished generating embeddings (check the plugin panel) Notes shorter than ~200 characters aren\u0026rsquo;t embedded Try broader search terms Slow initial queries # The first query after starting the server loads embeddings into memory. Subsequent queries are much faster.\n\u0026ldquo;Embedding dimension mismatch\u0026rdquo; # If you changed Smart Connections\u0026rsquo; embedding model, regenerate embeddings:\nDelete the .smart-env folder in your vault Restart Obsidian Wait for Smart Connections to regenerate embeddings Security Considerations # A few things to keep in mind:\nThe MCP server has read access to your entire vault. Only enable it for vaults you\u0026rsquo;re comfortable exposing to AI agents. Embeddings can leak information. While not human-readable, embeddings encode semantic content. Treat .smart-env with appropriate care. MCP requires explicit consent. Well-designed MCP clients ask before invoking tools. Don\u0026rsquo;t disable these safeguards. Alternatives and Trade-offs # This isn\u0026rsquo;t the only approach. Here are some alternatives:\nApproach Pros Cons Smart Connections + MCP (this guide) Privacy-first, free, semantic search Requires setup, local only Obsidian Copilot plugin Simpler setup, integrated UI Less flexible for agentic workflows RAG with cloud embeddings Higher quality embeddings, more models API costs, privacy concerns Direct file access No setup needed No semantic search, just keyword matching For my use case - privacy-sensitive notes that I want AI to search semantically - the Smart Connections + MCP approach hits the sweet spot.\nWhat\u0026rsquo;s Next? # The MCP ecosystem is growing rapidly. Some things I\u0026rsquo;m watching:\nBetter CLI integration: As Obsidian CLI matures, tighter AI → CLI workflows become possible Multi-vault support: Currently one vault per MCP server instance Embedding model options: Smart Connections Pro offers more model choices Two-way sync: AI agents that can both read and write through MCP Resources # Smart Connections Plugin - Official GitHub repository smart-connections-mcp - MCP server for Smart Connections Model Context Protocol - Official MCP specification Obsidian CLI Documentation - Release notes with CLI details Opencode - Open source AI coding agent with MCP support Kiro CLI - AWS\u0026rsquo;s AI development tool This setup has genuinely changed how I work with my notes. If you try it out, I\u0026rsquo;d love to hear what workflows you discover - always open for discussion on better approaches!\n","date":"12 February 2026","externalUrl":null,"permalink":"/posts/obsidian-smart-connections-mcp/","section":"Posts","summary":"","title":"Obsidian + Smart Connections + MCP: Building Your AI-Powered Knowledge System","type":"posts"},{"content":"","date":"12 February 2026","externalUrl":null,"permalink":"/categories/productivity/","section":"Categories","summary":"","title":"Productivity","type":"categories"},{"content":"","date":"12 February 2026","externalUrl":null,"permalink":"/tags/smart-connections/","section":"Tags","summary":"","title":"Smart-Connections","type":"tags"},{"content":"","date":"15 November 2025","externalUrl":null,"permalink":"/tags/async/","section":"Tags","summary":"","title":"Async","type":"tags"},{"content":"","date":"15 November 2025","externalUrl":null,"permalink":"/tags/asyncio/","section":"Tags","summary":"","title":"Asyncio","type":"tags"},{"content":"","date":"15 November 2025","externalUrl":null,"permalink":"/tags/concurrency/","section":"Tags","summary":"","title":"Concurrency","type":"tags"},{"content":"","date":"15 November 2025","externalUrl":null,"permalink":"/tags/conference/","section":"Tags","summary":"","title":"Conference","type":"tags"},{"content":"Below you\u0026rsquo;ll find a collection of my public speaking engagements, including conference talks, workshops, and hackathons.\n","date":"15 November 2025","externalUrl":null,"permalink":"/speaking/","section":"Public Speaking","summary":"","title":"Public Speaking","type":"speaking"},{"content":"","date":"15 November 2025","externalUrl":null,"permalink":"/tags/pycon/","section":"Tags","summary":"","title":"PyCon","type":"tags"},{"content":"","date":"15 November 2025","externalUrl":null,"permalink":"/tags/python/","section":"Tags","summary":"","title":"Python","type":"tags"},{"content":" Presentation # Topic: Async Python: Concurrency Without the Headaches Language: English Co-presenter: Mateusz Zaremba (Application Architect @ Orsted) Returning to PyCon Wroclaw with Mateusz for the second year running! This time we tackled asynchronous programming in Python - a topic that\u0026rsquo;s become essential for building high-performance applications, yet still feels intimidating for many developers.\nOur talk provided a hands-on introduction to async programming, explaining how concurrency really works under the hood. We covered:\nKey async concepts: async, await, and the event loop Common patterns like asyncio.gather and task coordination Real-world use cases: concurrent API calls and async database operations A live debugging session diving into a classic async pitfall Introduction to Asyncer, a modern library that simplifies async workflows For a deeper dive into the concepts we covered, check out my comprehensive guide to async Python concurrency.\nEvent # Date: June 14, 2025 Location: Concordia Design Wroclaw, Wyspa Slodowa 7, Wroclaw, Poland Website: https://2025.pyconwroclaw.com/ More # PyCon Wroclaw continues to grow as one of the premier Python events in Poland. The organizers - Maria Linnikova, Anton Caceres, Vadim Linnikov, Artur Smet, and the entire volunteer team - have built something special here. The conference maintains that perfect balance of high-quality technical content and genuine community warmth.\nIt was fantastic to see so many familiar faces from last year\u0026rsquo;s inaugural edition, along with plenty of new attendees discovering the conference for the first time. The questions and discussions after our talk showed just how much interest there is in understanding async Python properly rather than just cargo-culting patterns.\nBeing invited back to speak at a conference is always a meaningful endorsement, and I\u0026rsquo;m grateful for the opportunity to share knowledge with this community again. If you\u0026rsquo;re interested in Python conferences in Poland, PyCon Wroclaw should definitely be on your list.\nFor those who attended - what async challenges are you facing in your projects? I\u0026rsquo;d love to hear about real-world use cases where these patterns helped (or where you\u0026rsquo;re still struggling).\nRelated # Async Python Concurrency: A Practical Guide - Deep dive into the concepts from our talk Speaker: PyCon Wroclaw 2024 - Our first PyCon Wroclaw talk on Python CLIs ","date":"15 November 2025","externalUrl":null,"permalink":"/speaking/2025-pycon-wroclaw/","section":"Public Speaking","summary":"","title":"Speaker: PyCon Wroclaw 2025","type":"speaking"},{"content":" Presentation Overview # Recently, I had the opportunity to present a talk titled \u0026ldquo;Async Python: Concurrency Without The Headaches\u0026rdquo; at EuroPython 2025 alongside my colleague Mateusz Zaremba. Our presentation provided a practical guide to asynchronous programming in Python, breaking down complex concepts into digestible explanations with clear examples. As a DevOps Engineer at AWS and Mateusz as an Application Architect at Ørsted, we shared our expertise on making async Python more approachable and less intimidating.\nFor more information about the conference and my speaking engagement, check out my EuroPython 2025 speaking page.\nSpecial Thanks to EuroPython # I want to extend a heartfelt thank you to the EuroPython conference organizers, participants, and the entire EuroPython Society for making this event possible. The conference provided an incredible platform for knowledge sharing, networking, and community building. The dedication of the volunteers and staff created a welcoming environment that fostered learning and collaboration among Python enthusiasts from across Europe and beyond.\nKey Points from the Presentation # Understanding Async Programming # Why Async? Traditional synchronous code blocks execution, while asynchronous programming allows tasks to yield control, enabling non-blocking execution and improved efficiency. Concurrency vs. Parallelism: The presentation clarified the difference between these often confused concepts, explaining when each is appropriate. When to Use Async # Ideal for I/O-bound tasks: Network requests, file operations, and database queries Not recommended for: CPU-bound tasks like heavy computations, 3D rendering, or image/video processing Core Async Components # async def: Defines a coroutine function await: Pauses execution until an awaitable completes Event Loop: The \u0026ldquo;heart\u0026rdquo; of async execution that manages tasks Common Pitfalls # The presenters highlighted several common mistakes:\nForgetting to await coroutines Mixing blocking code with async code Not using debug mode when troubleshooting Practical Examples # The presentation included several code examples demonstrating:\nBasic coroutine definition and execution Using asyncio.gather() to run multiple tasks concurrently How mixing blocking code with async code can negate performance benefits Using asyncio debug mode to identify issues Real-World Use Cases # Async Python shines in several scenarios:\nReading files (using aiofiles) Downloading files from the web (using aiohttp) Running database queries (using SQLAlchemy with AsyncSession) Running web servers (using FastAPI) Making Async Simpler # The presenters introduced Asyncer, a library that simplifies working with async code:\n@asyncify: synchronous functions callable in async context @runnify: makes async functions easily callable from synchronous code Code Examples # Let\u0026rsquo;s look at some practical code examples to illustrate the concepts discussed in the presentation.\nSynchronous vs. Asynchronous Code # First, let\u0026rsquo;s compare synchronous and asynchronous approaches:\n# Synchronous (blocking) code import time def process_tasks(task_ids): results = [] # Each task blocks until complete for task_id in task_ids: print(f\u0026#34;Processing task {task_id}...\u0026#34;) time.sleep(1) # Simulate waiting result = f\u0026#34;Result for task {task_id}\u0026#34; results.append(result) return results # Takes 3 seconds total results = process_tasks([1, 2, 3]) Now, the asynchronous version:\n# Asynchronous (non-blocking) code import asyncio async def process_task(task_id): print(f\u0026#34;Processing task {task_id}...\u0026#34;) # Non-blocking await asyncio.sleep(1) return f\u0026#34;Result for task {task_id}\u0026#34; async def process_tasks(task_ids): # Create and gather all tasks tasks = [process_task(task_id=id) for id in task_ids] # Takes only ~1 second total return await asyncio.gather(*tasks) # Run the async function results = asyncio.run(process_tasks([1, 2, 3])) Basic Async Pattern # Here\u0026rsquo;s a simple example showing the basic async pattern:\nimport asyncio import time async def fetch_data(delay: int, name: str) -\u0026gt; str: print(f\u0026#34;Starting to fetch {name}...\u0026#34;) # Simulate API call with a delay await asyncio.sleep(delay) print(f\u0026#34;Finished fetching {name}!\u0026#34;) return f\u0026#34;Data from {name}\u0026#34; # Run the coroutine async def main() -\u0026gt; None: result = await fetch_data(delay=1, name=\u0026#34;API\u0026#34;) print(result) # Entry point asyncio.run(main()) Running Multiple Tasks Concurrently with gather() # The real power of async comes when running multiple tasks concurrently:\nimport asyncio import time async def fetch_data(delay: int, name: str) -\u0026gt; str: print(f\u0026#34;Starting to fetch {name}...\u0026#34;) # Simulate API call with a delay await asyncio.sleep(delay) print(f\u0026#34;Finished fetching {name}!\u0026#34;) return f\u0026#34;Data from {name}\u0026#34; async def main() -\u0026gt; None: start_time = time.time() # Run 3 tasks concurrently results = await asyncio.gather( fetch_data(delay=1, name=\u0026#34;API 1\u0026#34;), fetch_data(delay=4, name=\u0026#34;API 2\u0026#34;), fetch_data(delay=1, name=\u0026#34;API 3\u0026#34;), ) end_time = time.time() print(f\u0026#34;Total time: {int(end_time - start_time)} seconds\u0026#34;) print(f\u0026#34;Results: {results}\u0026#34;) # This will print: # Starting to fetch API 1... # Starting to fetch API 2... # Starting to fetch API 3... # Finished fetching API 1! # Finished fetching API 3! # Finished fetching API 2! # Total time: 4 seconds # Results: [\u0026#39;Data from API 1\u0026#39;, \u0026#39;Data from API 2\u0026#39;, \u0026#39;Data from API 3\u0026#39;] asyncio.run(main()) The Danger of Mixing Blocking Code with Async # Here\u0026rsquo;s what happens when you mix blocking code with async:\nimport asyncio import time async def fetch_data(delay: int, name: str) -\u0026gt; str: print(f\u0026#34;Starting to fetch {name}...\u0026#34;) # Non-blocking wait await asyncio.sleep(delay) print(f\u0026#34;Finished fetching {name}!\u0026#34;) return f\u0026#34;Data from {name}\u0026#34; async def my_operation(): print(\u0026#34;Other operation...\u0026#34;) # Blocking operation - this blocks the entire event loop! time.sleep(6) print(\u0026#34;Operation complete!\u0026#34;) return \u0026#34;Operation result\u0026#34; async def main() -\u0026gt; None: start_time = time.time() # Run tasks concurrently results = await asyncio.gather( my_operation(), fetch_data(delay=1, name=\u0026#34;API 1\u0026#34;), fetch_data(delay=4, name=\u0026#34;API 2\u0026#34;), fetch_data(delay=1, name=\u0026#34;API 3\u0026#34;), ) end_time = time.time() print(f\u0026#34;Total time: {int(end_time - start_time)} seconds\u0026#34;) print(f\u0026#34;Results: {results}\u0026#34;) # This will print: # Other operation... # Operation complete! (after 6 seconds) # Starting to fetch API 1... # Starting to fetch API 2... # Starting to fetch API 3... # Finished fetching API 1! # Finished fetching API 3! # Finished fetching API 2! # Total time: 10 seconds asyncio.run(main()) Using Debug Mode to Identify Issues # Debug mode can help identify issues like blocking operations:\nimport asyncio import time async def blocking_coroutine(): print(\u0026#34;Starting potentially blocking operation\u0026#34;) # This will be flagged in debug mode time.sleep(1) print(\u0026#34;Finished blocking operation\u0026#34;) async def main(): await blocking_coroutine() # Method 1: Set event loop debug mode asyncio.get_event_loop().set_debug(True) # Method 2: Run with debug enabled asyncio.run(main(), debug=True) # Method 3: Environment variable # PYTHONASYNCIODEBUG=1 python your_script.py Making Async Simpler with Asyncer # The Asyncer library makes working with async code much simpler:\nimport asyncio import time from asyncer import asyncify, runnify # Synchronous function to async @asyncify def slow_operation(): # Blocking operation time.sleep(1) return \u0026#34;Operation complete\u0026#34; # Make an async function easily callable from sync code @runnify async def fetch_data(): await asyncio.sleep(1) return \u0026#34;Data fetched\u0026#34; # Using asyncify and runnify together async def main(): # This won\u0026#39;t block the event loop! result = await slow_operation() print(result) # Call directly from synchronous code asyncio.run(main()) print(fetch_data()) # No need for asyncio.run() A Complete Real-World Example # Here\u0026rsquo;s a more complete example showing how to handle multiple API requests concurrently:\nimport asyncio import aiohttp import time from typing import List, Dict, Any async def fetch_api(session: aiohttp.ClientSession, url: str, name: str) -\u0026gt; Dict[str, Any]: \u0026#34;\u0026#34;\u0026#34;Fetch data from an API endpoint.\u0026#34;\u0026#34;\u0026#34; print(f\u0026#34;Fetching data from {name}...\u0026#34;) start = time.time() try: async with session.get(url) as response: if response.status == 200: data = await response.json() elapsed = time.time() - start print(f\u0026#34;Finished {name} in {elapsed:.2f} seconds\u0026#34;) return {\u0026#34;name\u0026#34;: name, \u0026#34;data\u0026#34;: data, \u0026#34;status\u0026#34;: \u0026#34;success\u0026#34;} else: elapsed = time.time() - start print(f\u0026#34;Error from {name}: HTTP {response.status} in {elapsed:.2f} seconds\u0026#34;) return {\u0026#34;name\u0026#34;: name, \u0026#34;status\u0026#34;: \u0026#34;error\u0026#34;, \u0026#34;code\u0026#34;: response.status} except Exception as e: elapsed = time.time() - start print(f\u0026#34;Exception from {name}: {str(e)} in {elapsed:.2f} seconds\u0026#34;) return {\u0026#34;name\u0026#34;: name, \u0026#34;status\u0026#34;: \u0026#34;exception\u0026#34;, \u0026#34;error\u0026#34;: str(e)} async def fetch_all_apis(urls: Dict[str, str]) -\u0026gt; List[Dict[str, Any]]: \u0026#34;\u0026#34;\u0026#34;Fetch data from multiple APIs concurrently.\u0026#34;\u0026#34;\u0026#34; async with aiohttp.ClientSession() as session: tasks = [] for name, url in urls.items(): tasks.append(fetch_api(session, url, name)) return await asyncio.gather(*tasks) async def main(): # Example API endpoints apis = { \u0026#34;users\u0026#34;: \u0026#34;https://jsonplaceholder.typicode.com/users\u0026#34;, \u0026#34;posts\u0026#34;: \u0026#34;https://jsonplaceholder.typicode.com/posts\u0026#34;, \u0026#34;comments\u0026#34;: \u0026#34;https://jsonplaceholder.typicode.com/comments\u0026#34;, \u0026#34;albums\u0026#34;: \u0026#34;https://jsonplaceholder.typicode.com/albums\u0026#34;, \u0026#34;photos\u0026#34;: \u0026#34;https://jsonplaceholder.typicode.com/photos\u0026#34;, } start = time.time() results = await fetch_all_apis(apis) elapsed = time.time() - start print(f\u0026#34;\\nAll APIs fetched in {elapsed:.2f} seconds\u0026#34;) # Process results for result in results: name = result[\u0026#34;name\u0026#34;] status = result[\u0026#34;status\u0026#34;] if status == \u0026#34;success\u0026#34;: data_count = len(result[\u0026#34;data\u0026#34;]) print(f\u0026#34;{name}: Successfully fetched {data_count} items\u0026#34;) else: print(f\u0026#34;{name}: Failed - {result.get(\u0026#39;error\u0026#39;, result.get(\u0026#39;code\u0026#39;, \u0026#39;Unknown error\u0026#39;))}\u0026#34;) if __name__ == \u0026#34;__main__\u0026#34;: asyncio.run(main()) This example demonstrates:\nConcurrent API requests with proper error handling Using context managers with async code Timing operations to measure performance benefits Processing results after all operations complete Key Takeaways # Async Python excels for I/O-bound tasks The event loop is single-threaded yet enables concurrency Be cautious when mixing blocking code with async code Async Python is powerful but can become complex if not approached carefully Consider whether async is appropriate for your specific use case When Not to Use Async # Simple, short-running scripts CPU-bound applications When dependent libraries aren\u0026rsquo;t async-ready When your team isn\u0026rsquo;t familiar with async patterns Useful Resources # For those looking to dive deeper into asynchronous Python programming, here are the invaluable resources shared during the presentation:\nOfficial Python asyncio Documentation - The comprehensive guide to Python\u0026rsquo;s asyncio library, including tutorials, reference materials, and examples.\nReal Python: Async IO in Python - An excellent tutorial that breaks down asyncio concepts with practical examples and clear explanations.\nReal Python: Python Async Features - A deeper dive into Python\u0026rsquo;s asynchronous features beyond just asyncio.\nAsyncer - A library that makes asyncio even more user-friendly, created by the author of FastAPI.\nPython Concurrency with asyncio - A comprehensive book on mastering asyncio for production applications.\nTrio - An alternative async library focused on usability and correctness.\nFeedback # Did you find this summary helpful? Have you implemented asyncio in your projects? I\u0026rsquo;d love to hear about your experiences with asynchronous Python programming!\nPlease share your thoughts through this feedback form.\n","date":"17 July 2025","externalUrl":null,"permalink":"/posts/async-python-concurrency/","section":"Posts","summary":"","title":"Async Python: Concurrency Without The Headaches","type":"posts"},{"content":"","date":"17 July 2025","externalUrl":null,"permalink":"/tags/europython/","section":"Tags","summary":"","title":"EuroPython","type":"tags"},{"content":"","date":"17 July 2025","externalUrl":null,"permalink":"/tags/prague/","section":"Tags","summary":"","title":"Prague","type":"tags"},{"content":"","date":"17 July 2025","externalUrl":null,"permalink":"/categories/python/","section":"Categories","summary":"","title":"Python","type":"categories"},{"content":" Presentation # Topic: Async Python: Concurrency Without the Headaches Language: English Date: July 17, 2025 Co-presenter: Mateusz Zaremba, Application Architect at Ørsted I presented on asynchronous programming in Python at EuroPython 2025 in Prague alongside my colleague Mateusz Zaremba. Our session demystified core async concepts like async, await, and the event loop, making them accessible to developers at all levels. The talk covered the asyncio ecosystem, common patterns like asyncio.gather and task coordination, and demonstrated practical implementations for concurrent API calls and database operations. We also introduced Asyncer, a modern library that simplifies async workflows for developers looking to enhance their async skills.\nThe presentation included:\nClear explanations of why and when to use async in Python Visual comparisons of synchronous vs. asynchronous workflows Live coding examples of common async patterns Real-world use cases for web applications, database queries, and task scheduling Tips on integrating sync and async code without blocking the event loop For a detailed summary of the presentation, including key takeaways and resources, check out my blog post on Async Python Concurrency.\nEvent # Date: July 14-20, 2025 Location: Prague Congress Centre, Prague, Czech Republic Website: https://ep2025.europython.eu/ Recording: Available after the event More # EuroPython is the world\u0026rsquo;s oldest volunteer-led Python conference, bringing together over 1,300 Python enthusiasts from around the globe. The 2025 edition in Prague featured:\n180+ expert speakers 7 days of Python content Keynote presentations from Brett Cannon (CPython Core Developer), Sebastián Ramírez (creator of FastAPI), and Savannah Ostrowski (CPython Core Developer \u0026amp; JIT Maintainer) Workshops, tutorials, and open spaces Networking opportunities and social events This prestigious event offered an excellent opportunity to connect with the global Python community and stay updated on the latest developments in the Python ecosystem.\n","date":"17 July 2025","externalUrl":null,"permalink":"/speaking/2025-europython/","section":"Public Speaking","summary":"","title":"Speaker: EuroPython 2025","type":"speaking"},{"content":"","date":"9 April 2025","externalUrl":null,"permalink":"/tags/ai/ml/","section":"Tags","summary":"","title":"AI/ML","type":"tags"},{"content":"","date":"9 April 2025","externalUrl":null,"permalink":"/tags/hallucinations/","section":"Tags","summary":"","title":"Hallucinations","type":"tags"},{"content":"","date":"9 April 2025","externalUrl":null,"permalink":"/tags/summit/","section":"Tags","summary":"","title":"Summit","type":"tags"},{"content":"","date":"9 April 2025","externalUrl":null,"permalink":"/tags/workshop/","section":"Tags","summary":"","title":"Workshop","type":"tags"},{"content":" Exciting News: AWS Summit Returns to Poland! # I\u0026rsquo;m thrilled to announce that after 6 years, AWS Summit is returning to Poland, and I\u0026rsquo;ll be co-hosting a workshop with Maciej Jędrzejczyk on reducing hallucinations in AI models!\nWorkshop # Topic: Reducing Hallucinations in AI Models (Workshop ID: WRK311) Language: Polish/English Co-presenter: Maciej Jędrzejczyk In this hands-on workshop, we\u0026rsquo;ll dive deep into practical techniques for reducing hallucinations in generative AI models. Participants will learn strategies to improve the accuracy and reliability of AI-generated content, with a focus on real-world applications and implementation.\nEvent # Date: May 6, 2025 Location: International Congress Centre Katowice, Poland Registration: Free of charge - Register here Summit Highlights # AWS Summit Poland 2025 promises to be an exceptional event with:\n90+ specialized sessions covering topics including AI/ML, Analytics, and digital transformation Keynote speakers including: Dr. Sherry Marcus (Director Applied Science in GenAI at AWS) Andrzej Horawa (AWS Country Manager, Poland) Magdalena Niedzielska (Deputy Director IT Shared Services, Polish Aviation Group/LOT Polish Airlines) Michal Smolinski (Co-founder \u0026amp; CTO, Radpoint) AWS GameDay: Generative AI - a gamified learning experience 1:1 meetings with AWS experts at the \u0026ldquo;Ask An AWS Expert\u0026rdquo; area Networking opportunities during the reception from 17:00 to 18:00 Startup Loft for connecting with the region\u0026rsquo;s top startups and investors AWS Community Lounge \u0026amp; Stage to learn from AWS Community members Schedule # From 08:00 | Doors open 09:00 - 10:45 | Morning Breakout Sessions 11:00 - 12:00 | Keynote 12:15 - 17:00 | Breakout Sessions \u0026amp; Activities 17:00 - 18:00 | Networking Reception Join Us! # If you\u0026rsquo;re interested in AWS technologies, cloud computing, or AI/ML, this is an event you won\u0026rsquo;t want to miss. The summit is completely free to attend, but registration is required.\nI\u0026rsquo;m looking forward to seeing you at our workshop and discussing how to make AI models more reliable and less prone to hallucinations. Feel free to reach out if you have any questions about the workshop or if you\u0026rsquo;d like to connect during the event!\nThis post was published on April 9, 2025, approximately one month before the AWS Summit Poland.\n","date":"9 April 2025","externalUrl":null,"permalink":"/speaking/2025-aws-summit-poland/","section":"Public Speaking","summary":"","title":"Workshop: AWS Summit Poland 2025","type":"speaking"},{"content":"","date":"5 April 2025","externalUrl":null,"permalink":"/tags/it-days/","section":"Tags","summary":"","title":"IT Days","type":"tags"},{"content":" Presentation # Topic: Async Python: Concurrency Without the Headaches Language: English I\u0026rsquo;ll be presenting on asynchronous programming in Python at the 16th edition of Warsaw IT Days (Warszawskie Dni Informatyki). My session will break down core async concepts like async, await, and the event loop in a clear, approachable way, showcasing practical examples and real-world use cases. The talk will cover the asyncio ecosystem, common patterns like asyncio.gather and task coordination, and demonstrate how to implement async for concurrent API calls and database operations. I\u0026rsquo;ll also introduce Asyncer, a modern library that simplifies async workflows for developers ready to take their skills to the next level.\nEvent # Date: April 4-5, 2025 Location: MiNI PW Building, Koszykowa 75, Warsaw (Hybrid: Online on April 4, In-person on April 5) Website: https://warszawskiedniinformatyki.pl/ Recording: Available after the event More # Warsaw IT Days is a landmark event in the Polish IT and Data Science community, attracting over 10,000 participants annually. The 2025 edition will feature:\n25+ thematic tracks 300+ presentations 3 formats: In-person, Online Live, and Video on Demand IT Job Fair with 50+ exhibitors Women in IT Days \u0026amp; Expo special track Networking opportunities, contests, and an afterparty The conference covers a wide range of topics including programming languages, cloud solutions, AI, cybersecurity, DevOps, data science, and career development in IT.\n","date":"5 April 2025","externalUrl":null,"permalink":"/speaking/2025-warsaw-it-days/","section":"Public Speaking","summary":"","title":"Speaker: Warsaw IT Days 2025","type":"speaking"},{"content":"","date":"5 April 2025","externalUrl":null,"permalink":"/tags/warsaw/","section":"Tags","summary":"","title":"Warsaw","type":"tags"},{"content":"","date":"27 February 2025","externalUrl":null,"permalink":"/tags/about/","section":"Tags","summary":"","title":"About","type":"tags"},{"content":"This page was made with Hugo and Blowfish, and is deployed on GitHub Pages.\nBuilding Static Websites with Blowfish and Hugo # Setup Process # While Hugo is the core framework that powers this site, Blowfish provides a convenient CLI tool called blowfish-tools that simplifies the setup process.\nInstall prerequisites:\nFirst, install Node.js on your local machine Install Hugo as it\u0026rsquo;s required by Blowfish Install Blowfish Tools:\nnpm install -g blowfish-tools Create a new site:\nblowfish new site your-site-name cd your-site-name This command automatically initializes Git, installs the Blowfish theme, and sets up the recommended configuration.\nCreate content:\nblowfish new post \u0026#34;My First Post\u0026#34; This command creates a new post with the proper front matter already configured.\nPreview your site locally:\nblowfish serve This starts the development server with live reload enabled.\nFor more detailed instructions and additional features, see the Blowfish documentation. The Blowfish CLI tool makes it much easier to get started while still leveraging the full power of Hugo under the hood.\nPublishing on GitHub Pages # This site is deployed using GitHub Pages with a GitHub Actions workflow. The source code is available at 3sztof/3sztof.github.io.\nHow It Works # Repository Structure:\nmain branch: Contains the source code (Hugo content, configuration, etc.) gh-pages branch: Contains the generated static site that GitHub serves GitHub Actions Workflow:\nWhen changes are pushed to the main branch, a GitHub Actions workflow automatically: Checks out the code Sets up Hugo Builds the site Deploys the generated static files to the gh-pages branch Setting Up Your Own:\nCreate a repository named username.github.io Push your Hugo site to the main branch Create a GitHub Actions workflow file at .github/workflows/hugo.yml Configure GitHub Pages to serve from the gh-pages branch For a complete example, check out the workflow configuration in this site\u0026rsquo;s repository.\nThis setup provides a smooth workflow where you only need to focus on creating content in the main branch, and the deployment happens automatically whenever you push changes.\nCustomizations # This site includes several customizations on top of the standard Blowfish theme:\nAnimated Background # The homepage features a custom animated background using a modified traffic.svg with colors matched to the Marvel theme palette - muted blues, soft golds, and occasional pinks.\nHero Layout with Background # A custom hero.html partial combines the hero card layout with an animated full-page background, giving the best of both layouts.\nKeyboard Shortcuts # Ctrl+K / Cmd+K: Open search (in addition to the default / key) Esc: Close search Arrow keys: Navigate search results Theme as Git Submodule # The Blowfish theme is managed as a Git submodule rather than copied directly into the repository, making updates easier and keeping the repo clean.\nBuilt with AI Assistance # Much of this site\u0026rsquo;s configuration, customization, and content was developed with the help of Opencode running Claude models on AWS Bedrock. The AI assisted with theme customization, layout modifications, SVG color adjustments, Hugo template overrides, and content drafting.\n","date":"27 February 2025","externalUrl":null,"permalink":"/about/page/","section":"Abouts","summary":"","title":"About This Site","type":"about"},{"content":"","date":"27 February 2025","externalUrl":null,"permalink":"/about/","section":"Abouts","summary":"","title":"Abouts","type":"about"},{"content":"","date":"27 February 2025","externalUrl":null,"permalink":"/tags/blowfish/","section":"Tags","summary":"","title":"Blowfish","type":"tags"},{"content":"","date":"27 February 2025","externalUrl":null,"permalink":"/tags/collaboration/","section":"Tags","summary":"","title":"Collaboration","type":"tags"},{"content":"","date":"27 February 2025","externalUrl":null,"permalink":"/tags/contributions/","section":"Tags","summary":"","title":"Contributions","type":"tags"},{"content":"","date":"27 February 2025","externalUrl":null,"permalink":"/tags/edit/","section":"Tags","summary":"","title":"Edit","type":"tags"},{"content":"","date":"27 February 2025","externalUrl":null,"permalink":"/tags/git/","section":"Tags","summary":"","title":"Git","type":"tags"},{"content":"","date":"27 February 2025","externalUrl":null,"permalink":"/tags/github/","section":"Tags","summary":"","title":"Github","type":"tags"},{"content":"","date":"27 February 2025","externalUrl":null,"permalink":"/tags/github-actions/","section":"Tags","summary":"","title":"Github-Actions","type":"tags"},{"content":"","date":"27 February 2025","externalUrl":null,"permalink":"/tags/hugo/","section":"Tags","summary":"","title":"Hugo","type":"tags"},{"content":"","date":"27 February 2025","externalUrl":null,"permalink":"/tags/nodejs/","section":"Tags","summary":"","title":"Nodejs","type":"tags"},{"content":"","date":"27 February 2025","externalUrl":null,"permalink":"/tags/open-source/","section":"Tags","summary":"","title":"Open-Source","type":"tags"},{"content":"","date":"27 February 2025","externalUrl":null,"permalink":"/tags/pull-request/","section":"Tags","summary":"","title":"Pull-Request","type":"tags"},{"content":"","date":"27 February 2025","externalUrl":null,"permalink":"/tags/static-site/","section":"Tags","summary":"","title":"Static-Site","type":"tags"},{"content":" Help Improve This Website # This website is open-source and available on GitHub at 3sztof/3sztof.github.io. Suggestions, corrections, and improvements are always welcome! If you\u0026rsquo;ve found a typo, have an idea for new content, or want to suggest improvements, there are several ways to contribute.\nHow to Suggest Edits # Option 1: Opening a GitHub Issue # The easiest way to suggest changes is by opening a GitHub issue. You can use our issue templates to make the process easier:\nQuick Links to Create an Issue: # 📝 Suggest Content Change or Correction 🐛 Report a Bug or Display Issue 🆓 Open a Blank Issue Manual Process: # Go to the repository: Visit https://github.com/3sztof/3sztof.github.io\nNavigate to Issues: Click on the \u0026ldquo;Issues\u0026rdquo; tab near the top of the repository page\nCreate a new issue: Click the green \u0026ldquo;New issue\u0026rdquo; button and select an appropriate template\nProvide details:\nUse a clear, descriptive title Fill in the template with specific information about your suggestion Include the URL of the page you\u0026rsquo;re referring to For content corrections, include both the current text and your suggested revision You can use Markdown formatting in your issue description Submit: Click \u0026ldquo;Submit new issue\u0026rdquo;\nExample Issue # Here\u0026rsquo;s an example of a well-formatted issue:\nTitle: Typo on About page - \u0026#34;descriptn\u0026#34; should be \u0026#34;description\u0026#34; Description: On the About page (https://3sztof.github.io/about/page/), there\u0026#39;s a typo in the second paragraph: Current text: \u0026#34;TODO: add a descriptn how this site is built\u0026#34; Suggested change: \u0026#34;TODO: add a description how this site is built\u0026#34; Option 2: Creating a Pull Request # If you\u0026rsquo;re comfortable with Git and Hugo, you can directly propose changes by:\nFork the repository: Click the \u0026ldquo;Fork\u0026rdquo; button at the top right of the repository page\nClone your fork:\ngit clone https://github.com/YOUR-USERNAME/3sztof.github.io.git Create a branch:\ngit checkout -b fix-typo Make your changes: Edit the relevant files\nCommit and push:\ngit commit -am \u0026#34;Fix typo in about page\u0026#34; git push origin fix-typo Create a pull request: Go to the original repository and click \u0026ldquo;New pull request\u0026rdquo;, then select your branch\nThe pull request will automatically use our PR template to help you provide all necessary information\nContent Guidelines # When suggesting content changes, please:\nKeep the same writing style as the rest of the site Ensure technical accuracy Include references or sources if adding new information Follow the existing formatting conventions Thank You! # Your contributions help make this site better for everyone. Thank you for taking the time to suggest improvements!\n","date":"27 February 2025","externalUrl":null,"permalink":"/about/suggest-edits/","section":"Abouts","summary":"","title":"Suggest Edits","type":"about"},{"content":"","date":"27 February 2025","externalUrl":null,"permalink":"/tags/web-development/","section":"Tags","summary":"","title":"Web-Development","type":"tags"},{"content":"Hey, my name is Krzysztof! You can call me Chris if it’s easier for you - Krzysztof is just \u0026lsquo;Christopher\u0026rsquo; written in a funky Polish way. 😉\nI\u0026rsquo;m a DevOps Engineer currently working for AWS (Amazon Web Services) Professional Services. In my day to day work, I\u0026rsquo;m assisting AWS\u0026rsquo; largest customers on their cloud journey with both my technical (coding, architecting) and consulting skills.\nIn my \u0026ldquo;past live\u0026rdquo;, I\u0026rsquo;ve been a robotics engineer. I have switched to IT after being involved in Industrial Internet of Things / Physics High Performance Computing projects in my previous work experience.\nWork stuff # I\u0026rsquo;m a DevOps Consultant at AWS Professional Services Global Competency Center in Warsaw! 🇵🇱\nIn my current role - as a DevOps engineer, I’m helping AWS’ largest customers on their journey to the cloud. Usually, I’m developing Serverless backend software (mostly in Python), designing Infrastructure as Code (CF \u0026amp; SAM / TF / CDK) with a strong accent on Security (preventive and reactive controls, DevSecOps).\nMy superpower is insisting on the highest standards in software development teams. By highest standards, I mean both the way of working (DevSecOps culture) and technical excellence - building production-ready, safe and operations-friendly products.\nPrivate stuff # I’m passionate about music - I love to explore different aspects of it (theory, genres, folk etc) and discuss / exchange discoveries with my peers. I spend most of my free time playing my guitars \u0026amp; piano, tinkering with my 3D printers or writing some code for my pet projects.\nAs you might have already guessed, I’m a big nerd. 🤓\nCertification flex (yeah I know..) # I love learning new things, here are some certifications / skill badges that I\u0026rsquo;ve earned!\nAmazon Web Services (AWS) # Scaled Agile (SAFe) # ","date":"21 February 2025","externalUrl":null,"permalink":"/about/author/","section":"Abouts","summary":"","title":"About Me","type":"about"},{"content":"","date":"21 February 2025","externalUrl":null,"permalink":"/tags/author/","section":"Tags","summary":"","title":"Author","type":"tags"},{"content":"","date":"21 February 2025","externalUrl":null,"permalink":"/tags/certifications/","section":"Tags","summary":"","title":"Certifications","type":"tags"},{"content":"","date":"21 February 2025","externalUrl":null,"permalink":"/tags/cloud/","section":"Tags","summary":"","title":"Cloud","type":"tags"},{"content":"","date":"21 February 2025","externalUrl":null,"permalink":"/tags/devops/","section":"Tags","summary":"","title":"DevOps","type":"tags"},{"content":"","date":"21 February 2025","externalUrl":null,"permalink":"/tags/professional-services/","section":"Tags","summary":"","title":"Professional-Services","type":"tags"},{"content":" Presentation # Topic: Building Python CLIs in 2024 does not have to be painful (feat. Typer and uv) Language: English Co-presenter: Mateusz Zaremba (Application Architect @ Ørsted) In our \u0026ldquo;Dynamic Duo\u0026rdquo; presentation with Mateusz Zaremba, we focused on sharing best practices for building and delivering intuitive and reliable command line interface applications in Python. We demonstrated how modern tools like Typer and uv can significantly improve the developer experience when creating CLI applications.\nOur talk covered:\nCommon pain points in traditional CLI development with Python How Typer simplifies command creation with type annotations Using uv for faster dependency management and packaging Best practices for user-friendly CLI design Live demonstrations of building a CLI from scratch Packaging and distribution strategies for Python CLI tools We encouraged developers to try these amazing, open-source tools that make CLI development more enjoyable and productive in 2024 and beyond.\nDemo Project # As part of our presentation, we built a fun demo project called \u0026ldquo;memer-cli\u0026rdquo; - a command line tool for generating memes. This project demonstrates the concepts we discussed in a practical, engaging way.\nGitHub Repository: github.com/zaremb/memer-cli\nThe repository includes all the code we demonstrated during our talk and serves as a reference implementation for anyone looking to build their own Python CLI tools using Typer and uv.\nEvent # Date: November 30, 2024 Location: Concordia Design Wrocław, Wyspa Słodowa 7, Wrocław, Poland Website: https://pyconwroclaw.com/ Recording: TBD More # PyCon Wrocław 2024 was the inaugural edition of this conference, bringing together Python enthusiasts from across Europe. The event featured exceptional speakers including Łukasz Langa (CPython Developer in Residence) and Antonio Cuni (Principal Software Engineer at Anaconda).\nThe conference was organized by a dedicated team including Maria Linnikova, Anton Cáceres, Vadim Linnikov, and Artur Smęt, along with many amazing volunteers who made this outstanding event possible.\nThe venue, Concordia Design Wrocław, provided a beautiful setting with a magical atmosphere as the holiday season approached. The conference offered a perfect blend of technical content, networking opportunities, and community spirit.\nI\u0026rsquo;m grateful for the opportunity to have been part of this first-ever PyCon Wrocław and to contribute to the vibrant Python community in Poland. Looking forward to seeing how this conference grows in the coming years!\n","date":"30 November 2024","externalUrl":null,"permalink":"/speaking/2024-pycon-wroclaw/","section":"Public Speaking","summary":"","title":"Speaker: PyCon Wrocław 2024","type":"speaking"},{"content":"","date":"30 November 2024","externalUrl":null,"permalink":"/tags/typer/","section":"Tags","summary":"","title":"Typer","type":"tags"},{"content":"","date":"30 November 2024","externalUrl":null,"permalink":"/tags/uv/","section":"Tags","summary":"","title":"Uv","type":"tags"},{"content":"","date":"29 May 2024","externalUrl":null,"permalink":"/tags/lambda-powertools/","section":"Tags","summary":"","title":"Lambda Powertools","type":"tags"},{"content":"","date":"29 May 2024","externalUrl":null,"permalink":"/tags/pydantic/","section":"Tags","summary":"","title":"Pydantic","type":"tags"},{"content":"","date":"29 May 2024","externalUrl":null,"permalink":"/tags/serverless/","section":"Tags","summary":"","title":"Serverless","type":"tags"},{"content":" Presentation # Topic: Lambda Powertools + Pydantic - Your Best Friends for Serverless Development Language: English In a dynamic-duo presentation with Mateusz Zaremba, we addressed a common pain point in serverless development: the repetitive task of handling incoming events, parsing them, and directing them to the right functions. Our talk focused on how Lambda Powertools and Pydantic can work together as the ultimate allies in the serverless world.\nWe demonstrated how Lambda Powertools provides a suite of utilities including monitoring, loggers, and tracers designed to simplify serverless workflows on AWS. These tools eliminate the need for developers to reinvent the wheel with each Lambda function by providing standardized event processing, logging, and error handling mechanisms.\nWe also showed how Pydantic, a lightweight data validation library, seamlessly integrates with Lambda Powertools to provide prebuilt models for common event sources, ensuring automatic request validation and structured data processing.\nThe presentation included practical demonstrations and examples of how these tools work together to:\nStreamline event processing and reduce boilerplate code Enhance reliability through robust error handling Boost productivity with automatic request validation Improve developer experience with static typing in boto3 As promised, we concluded with a live demo showing these concepts in action, giving attendees practical insights they could immediately apply to their own serverless projects.\nEvent # Date: 29th of August - 1st of September, 2024 Location: Wrocław, Poland Website: https://pl.pycon.org/2024/ Recording: TBD Resources # Source code: All demo code from the presentation is available on GitHub: github.com/3sztof/pycon-2024-powertools-demo\nPersonal Reflections # PyCon Poland 2024 was an amazing experience full of great conversations and insights. Some highlights include:\nIncredible keynotes by CPython core developers Łukasz Langa and Pablo Galindo Salgado Engaging late-evening conversations that went way beyond Python Wonderful support from Ørsted for PyLadies Poland Great networking with the Splunk team who sponsored the event This conference was special in many ways, bringing together a vibrant community of Python enthusiasts. The exchanges, insights, and connections made during the event were truly inspiring. Already looking forward to the next PyCon!\nPhoto Gallery # Announcement of our talk at PyCon Poland 2024 Highlights from PyCon Poland 2024 ","date":"29 May 2024","externalUrl":null,"permalink":"/speaking/2024-pycon-poland/","section":"Public Speaking","summary":"","title":"Speaker: PyCon Poland 2024","type":"speaking"},{"content":"","date":"21 March 2024","externalUrl":null,"permalink":"/tags/infrastructure/","section":"Tags","summary":"","title":"Infrastructure","type":"tags"},{"content":"","date":"21 March 2024","externalUrl":null,"permalink":"/tags/scaling/","section":"Tags","summary":"","title":"Scaling","type":"tags"},{"content":" Presentation # Topic: Scaling on AWS for Your First 10 Million Users Language: English Co-presenter: Monika Nowakowska (AWS Associate Solution Architect) In this presentation, we dive into different aspects and challenges of scaling applications deployed on Amazon Web Services (AWS) cloud, through a DevOps lens. We cover infrastructure scaling strategies for rapid user growth without compromising performance, deployment automation techniques, and cost optimization approaches.\nKey topics include:\nInfrastructure scaling patterns for handling millions of users Deployment automation best practices Cost reduction strategies while maintaining performance Real-world examples of scalable architectures on AWS Event # Date: March 21, 2024 Time: 18:00 (6 PM) CET Location: Andersen\u0026rsquo;s office in Warsaw, Poland Website: Registration Link Organizer: Andersen Lab \u0026amp; AWS Other Speakers # Viktor Vedmich (Senior Developer Advocate)\nTopic: re:Cap of re:Invent 2023 – or What\u0026rsquo;s New on AWS\nAn in-depth overview of AWS re:Invent 2023 announcements and innovations, covering the latest advances in cloud infrastructures, Machine Learning, AI, and serverless technologies.\nArtsem Maliutsin (DevSecOps Engineer)\nTopic: Kubernetes Security: Best Practices at Andersen\nA comprehensive set of strategies to improve the security and efficiency of Kubernetes deployments, with analysis of Andersen\u0026rsquo;s best practices that played a decisive role in the success of their projects.\nMore # This DevOps meetup brought together cloud and infrastructure professionals from the Warsaw area for an evening of knowledge sharing and networking. The event was hosted at Andersen\u0026rsquo;s Warsaw office and featured presentations on AWS innovations, Kubernetes security, and scaling applications on AWS.\nIf you attended this event and would like to discuss any of the topics further, feel free to reach out to me directly.\n","date":"21 March 2024","externalUrl":null,"permalink":"/speaking/2024-andersen-devops-meetup/","section":"Public Speaking","summary":"","title":"Speaker: Andersen DevOps Meetup 2024","type":"speaking"},{"content":"","date":"6 December 2023","externalUrl":null,"permalink":"/tags/air-quality/","section":"Tags","summary":"","title":"Air Quality","type":"tags"},{"content":" Mentoring # I served as an AWS hack-mentor at the Tech to the Rescue Air Quality Hackathon, the world\u0026rsquo;s largest online pro-bono hackathon organized by Tech to The Rescue in collaboration with AWS. The event brought together over 170 tech teams from 27 countries to build innovative solutions addressing air pollution challenges.\nAreas of responsibility:\nProviding technical guidance on AWS services and cloud architecture Helping teams implement machine learning and AI solutions for air quality data analysis Supporting participants with cloud deployment strategies Advising on scalable and cost-effective approaches for nonprofit use cases Tech stack: AWS Cloud, Machine Learning, AI, Data Analytics\nEvent # Date: 6-8 Decemember, 2023 Location: Online, Global Website: https://techtotherescue.org/campaign/air-quality-hackathon/ More # The hackathon focused on 7 real challenges from nonprofits working to improve access to quality air quality data and raise awareness about air pollution as a \u0026ldquo;silent killer\u0026rdquo;. Participants had access to exclusive AI workshops, keynotes, and mentorship from experts in ML, AI, and Cloud technologies.\nThe event successfully connected tech talent with meaningful environmental causes, creating solutions that help fight air pollution while establishing a new industry standard for tech volunteering.\n","date":"6 December 2023","externalUrl":null,"permalink":"/speaking/2023-air-quality-hackathon/","section":"Public Speaking","summary":"","title":"AWS Hack-Mentor: Tech to the Rescue Air Quality Hackathon","type":"speaking"},{"content":"","date":"6 December 2023","externalUrl":null,"permalink":"/tags/hackathon/","section":"Tags","summary":"","title":"Hackathon","type":"tags"},{"content":"","date":"6 December 2023","externalUrl":null,"permalink":"/tags/mentoring/","section":"Tags","summary":"","title":"Mentoring","type":"tags"},{"content":"","date":"6 December 2023","externalUrl":null,"permalink":"/tags/tech-for-good/","section":"Tags","summary":"","title":"Tech for Good","type":"tags"},{"content":"","date":"14 June 2023","externalUrl":null,"permalink":"/tags/women-in-tech/","section":"Tags","summary":"","title":"Women-in-Tech","type":"tags"},{"content":" Workshop # Topic: Learn Python on AWS Language: Bilingual - English + Polish Self-paced: AWS Workshops Platform Event # Date: 14-15th of June, 2023 Location: Warsaw, Poland Website: https://2023.womenintechsummit.pl/ Recording: Unfortunately, the recording is corrupted (accordign to the organizers) Personal Note # I had the privilege of hosting the \u0026ldquo;Learn to Code on Amazon Web Services (AWS)\u0026rdquo; workshop, and it was truly an honor to support such a motivated and talented group of ~40 attendees. 👩‍💻 The feedback was overwhelmingly positive, with approximately 75% of participants rating the workshop\u0026rsquo;s quality as \u0026ldquo;far above average\u0026rdquo; in our satisfaction survey. To all the attendees: I\u0026rsquo;m immensely grateful for your enthusiasm and engagement, you are AWSome! Thank you for inspiring us to develop the workshop further based on your feedback!\nI was particularly impressed by the passion displayed by the student participants. Out of the ~11,200 attendees, ~4,500 were students who received grants to attend. It fills me with hope for a more diverse and inclusive future in the tech sector! 👩‍💻👩‍🔬👨‍💻\nTalking about empowerment, congratulations to my incredible coworkers: Emilia Smolko, Marta Milejska, Anna Jabłońska, Sandra Cervantes, Magdalena Rempuszewska \u0026amp; Małgorzata Zielińska for being recognized among the \u0026ldquo;Top 100 Women in Cloud Computing\u0026rdquo; during the Summit. It\u0026rsquo;s truly inspiring to work alongside such exceptional professionals! 🌟\nLastly, I\u0026rsquo;d like to express my sincere appreciation to Tala Qraitem, Shubhangi Mali, and Mateusz Kępka for their invaluable support during the workshop. Special thanks to Charles Roberts for building it from scratch. And of course, a big shoutout to all the inspiring and talented individuals I had the pleasure of meeting at the summit.\nIt was a true pleasure connecting with each and every one of you.\nMore # My LinkedIn post ","date":"14 June 2023","externalUrl":null,"permalink":"/speaking/2023-women-in-tech-summit/","section":"Public Speaking","summary":"","title":"Workshop Organizer: Women in Tech Summit 2023","type":"speaking"},{"content":"","date":"9 June 2022","externalUrl":null,"permalink":"/tags/auto-remediation/","section":"Tags","summary":"","title":"Auto-Remediation","type":"tags"},{"content":"","date":"9 June 2022","externalUrl":null,"permalink":"/tags/secops/","section":"Tags","summary":"","title":"SecOps","type":"tags"},{"content":"","date":"9 June 2022","externalUrl":null,"permalink":"/tags/security/","section":"Tags","summary":"","title":"Security","type":"tags"},{"content":" Presentation # Topic: SecOps on AWS: Large Scale Cloud Threat Prevention, Detection and Auto-Remediation Language: English This session introduced listeners to the concept of SecOps (DevSecOps) and addressed the scale of cloud threat detection and prevention that requires proper automation. I discussed the most important AWS security automation solutions and shared a customer success story from a large polymer manufacturing business that had been targeted by state-sponsored hackers attempting to steal their technology — a real project that I have delivered as a part of AWS Professional Services. The presentation demonstrated how automated security solutions can effectively protect cloud environments against sophisticated, large scale threats.\nEvent # Date: 9th of June, 2022 Location: Warsaw, Poland Website: https://www.codeeurope.pl Recording: Unfortunately, the recording is corrupted (accordign to the organizers) More # My LinkedIn post ","date":"9 June 2022","externalUrl":null,"permalink":"/speaking/2022-code-europe/","section":"Public Speaking","summary":"","title":"Speaker: CodeEurope 2022","type":"speaking"},{"content":"","date":"3 March 2022","externalUrl":null,"permalink":"/tags/cdk/","section":"Tags","summary":"","title":"CDK","type":"tags"},{"content":"","date":"3 March 2022","externalUrl":null,"permalink":"/tags/iac/","section":"Tags","summary":"","title":"IaC","type":"tags"},{"content":" Presentation # Topic: AWS CDK: Mniej Kodu, Lepsza Infrastruktura Language: Polish Event # Date: 3th of March, 2022 Location: Warsaw, Poland Recording: YouTube More # My LinkedIn post ","date":"3 March 2022","externalUrl":null,"permalink":"/speaking/2022-streaming-with-aws/","section":"Public Speaking","summary":"","title":"Twitch Stream Speaker: 'Czwartkowy Cloud-Tech z AWS Polska' [PL]","type":"speaking"},{"content":"","date":"14 September 2019","externalUrl":null,"permalink":"/tags/bosch/","section":"Tags","summary":"","title":"Bosch","type":"tags"},{"content":" Mentoring # I have coached and helped the HackYeah hackathon teams in Bosch Rexroth\u0026rsquo;s software/hardware/ai challenge focused on implementing position feedback for EFC (frequency converter) driven motion axis based on visual information from a camera (image recognition, axis position tracking).\nAreas of responsibility:\npreparation of the challenge software and development environments for hackathon participants 24h (x2) support during the hackathon Python / JavaScript / NodeJS / NodeRED / Open Core Engineering mentoring for the teams Tech stack: Python, JavaScript, Bosch Rexroth Open Core Engineering\nEvent # Date: 14th of November, 2019 Location: Warsaw, Poland Website: https://hackyeah.pl More # My LinkedIn post ","date":"14 September 2019","externalUrl":null,"permalink":"/speaking/2019-hackyeah-hackathon/","section":"Public Speaking","summary":"","title":"Mentor: Hack Yeah 2019","type":"speaking"},{"content":"","date":"14 September 2019","externalUrl":null,"permalink":"/tags/rexroth/","section":"Tags","summary":"","title":"Rexroth","type":"tags"},{"content":"Below you\u0026rsquo;ll find a collection of my mysical discoveries, projects and thoughts on all-things-music.\n","date":"1 January 1970","externalUrl":null,"permalink":"/music/","section":"Music","summary":"","title":"Music","type":"music"},{"content":"","date":"1 January 1970","externalUrl":null,"permalink":"/tags/music/","section":"Tags","summary":"","title":"Music","type":"tags"},{"content":"","date":"1 January 1970","externalUrl":null,"permalink":"/tags/todo/","section":"Tags","summary":"","title":"TODO","type":"tags"},{"content":" Presentation # Topic: TODO Language: TODO TODO: Fill in presentation details\nEvent # Date: TODO Location: TODO Website: TODO Recording: TODO More # TODO: Add more information if available\n","date":"1 January 1970","externalUrl":null,"permalink":"/speaking/2024-python-summit/","section":"Public Speaking","summary":"","title":"TODO: Python Summit 2024","type":"speaking"},{"content":" Project # Title: TODO Release Date: TODO Genre: TODO TODO: Fill in project details\nLinks # Streaming: TODO Download: TODO Music Video: TODO Credits # Composition: TODO Performance: TODO Production: TODO More # TODO: Add more information if available\n","date":"1 January 1970","externalUrl":null,"permalink":"/music/2023-sample-release/","section":"Music","summary":"","title":"TODO: Sample Music Release","type":"music"},{"content":"All content from this website.\n","externalUrl":null,"permalink":"/all/","section":"All Content","summary":"","title":"All Content","type":"all"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]